#!/usr/bin/env python3
"""
ä½¿ç”¨SCRFDæ£€æµ‹ç›‘æ§å›¾åƒä¸­çš„äººè„¸
SCRFD: Sample and Computation Redistribution for Efficient Face Detection
ç‰¹ç‚¹ï¼šè½»é‡ã€å¿«é€Ÿã€å‡†ç¡®ï¼Œé€‚åˆç›‘æ§åœºæ™¯
"""

import os
import cv2
import numpy as np
from pathlib import Path
import argparse
from tqdm import tqdm

class SCRFDFaceDetector:
    """SCRFDäººè„¸æ£€æµ‹å™¨"""
    
    def __init__(self, model_path=None, conf_threshold=0.5, nms_threshold=0.5, 
                 use_gpu=False, model_name='scrfd_10g', input_size=(1280, 1280)):
        """
        åˆå§‹åŒ–SCRFDæ£€æµ‹å™¨
        
        Args:
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤æ¨¡å‹
            conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
            nms_threshold: NMSé˜ˆå€¼
            use_gpu: æ˜¯å¦ä½¿ç”¨GPU
            model_name: æ¨¡å‹åç§°ï¼Œå¯é€‰: 'scrfd_500m', 'scrfd_2.5g', 'scrfd_10g'
            input_size: è¾“å…¥å°ºå¯¸ (width, height)
        """
        self.conf_threshold = conf_threshold
        self.nms_threshold = nms_threshold
        self.use_gpu = use_gpu
        self.model_name = model_name
        self.fixed_input_size = input_size  # ä¿å­˜å›ºå®šçš„è¾“å…¥å°ºå¯¸
        self.model_path = model_path  # ä¿å­˜æ¨¡å‹è·¯å¾„
        
        print(f"ğŸ”„ åˆå§‹åŒ–SCRFDæ£€æµ‹å™¨ (æ¨¡å‹: {model_name}, è¾“å…¥å°ºå¯¸: {input_size})...")
        self.net = self._load_model()
        print("âœ… SCRFDæ£€æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _load_model(self):
        """
        åŠ è½½SCRFDæ¨¡å‹
        """
        try:
            import onnxruntime as ort
            
            # ç¡®å®šæ¨¡å‹è·¯å¾„
            model_path = self.model_path
            
            # å¦‚æœæ²¡æœ‰æŒ‡å®šæ¨¡å‹è·¯å¾„ï¼Œä½¿ç”¨å†…ç½®çš„æ¨¡å‹åç§°
            if model_path is None:
                # æœ¬åœ°æ¨¡å‹æ–‡ä»¶è·¯å¾„
                model_dir = os.path.join(os.path.expanduser("~"), ".scrfd_models")
                os.makedirs(model_dir, exist_ok=True)
                model_path = os.path.join(model_dir, f"{self.model_name}.onnx")
                
                if not os.path.exists(model_path):
                    print(f"âš ï¸  æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
                    print(f"ğŸ’¡ è¯·ä»ä»¥ä¸‹åœ°å€ä¸‹è½½æ¨¡å‹:")
                    print(f"   https://github.com/deepinsight/insightface/releases/download/v0.7/scrfd_10g.onnx")
                    print(f"ğŸ’¡ æˆ–è¿è¡Œ: wget https://github.com/deepinsight/insightface/releases/download/v0.7/scrfd_10g.onnx -O {model_path}")
                    raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            
            # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
            if not os.path.exists(model_path):
                raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            
            print(f"ğŸ“ åŠ è½½æ¨¡å‹: {os.path.basename(model_path)}")
            
            # é…ç½®ONNX Runtime
            providers = ['CUDAExecutionProvider', 'CPUExecutionProvider'] if self.use_gpu else ['CPUExecutionProvider']
            
            # åˆ›å»ºæ¨ç†ä¼šè¯
            session = ort.InferenceSession(model_path, providers=providers)
            
            # è·å–è¾“å…¥ä¿¡æ¯
            self.input_name = session.get_inputs()[0].name
            
            # é‡è¦ï¼šä½¿ç”¨å›ºå®šçš„è¾“å…¥å°ºå¯¸ï¼Œä¸è¦ä»æ¨¡å‹ä¸­è·å–åŠ¨æ€å°ºå¯¸
            # SCRFDæ¨¡å‹æ”¯æŒåŠ¨æ€è¾“å…¥ï¼Œä½†æˆ‘ä»¬éœ€è¦æŒ‡å®šå›ºå®šå°ºå¯¸
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼Œä½¿ç”¨å›ºå®šè¾“å…¥å°ºå¯¸: {self.fixed_input_size}")
            
            return session
            
        except ImportError:
            print("âŒ éœ€è¦å®‰è£… onnxruntime")
            print("å®‰è£…å‘½ä»¤: pip install onnxruntime")
            if self.use_gpu:
                print("GPUç‰ˆæœ¬: pip install onnxruntime-gpu")
            raise
        except Exception as e:
            print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
            raise
    
    def _preprocess(self, image):
        """é¢„å¤„ç†å›¾åƒ"""
        # ç¡®ä¿è¾“å…¥å°ºå¯¸æ˜¯æœ‰æ•ˆçš„æ•´æ•°
        target_width = int(self.fixed_input_size[0])
        target_height = int(self.fixed_input_size[1])
        
        # è°ƒæ•´å°ºå¯¸
        img_resized = cv2.resize(image, (target_width, target_height))
        
        # è½¬æ¢ä¸ºRGB
        img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)
        
        # å½’ä¸€åŒ– (SCRFDä½¿ç”¨çš„å½’ä¸€åŒ–æ–¹å¼)
        img_normalized = img_rgb.astype(np.float32)
        img_normalized = (img_normalized - 127.5) / 128.0
        
        # è°ƒæ•´ç»´åº¦é¡ºåº: HWC -> NCHW
        img_transposed = np.transpose(img_normalized, (2, 0, 1))
        img_batch = np.expand_dims(img_transposed, axis=0)
        
        return img_batch, img_resized
    
    def _postprocess(self, outputs, original_size, resized_size):
        """åå¤„ç†æ£€æµ‹ç»“æœ"""
        # SCRFDè¾“å‡ºæœ‰9ä¸ªï¼Œåˆ†åˆ«æ˜¯ä¸åŒå°ºåº¦çš„åˆ†ç±»åˆ†æ•°ã€è¾¹ç•Œæ¡†å’Œå…³é”®ç‚¹
        # æˆ‘ä»¬éœ€è¦å¤„ç†æ‰€æœ‰å°ºåº¦çš„è¾“å‡º
        
        all_detections = []
        
        # SCRFDè¾“å‡ºç´¢å¼•ï¼š3ä¸ªå°ºåº¦ï¼Œæ¯ä¸ªå°ºåº¦æœ‰3ä¸ªè¾“å‡ºï¼ˆåˆ†ç±»ã€è¾¹ç•Œæ¡†ã€å…³é”®ç‚¹ï¼‰
        # å…±9ä¸ªè¾“å‡ºï¼š[score1, score2, score3, bbox1, bbox2, bbox3, landmark1, landmark2, landmark3]
        
        # éå†3ä¸ªå°ºåº¦
        for scale_idx in range(3):
            score_idx = scale_idx  # åˆ†ç±»åˆ†æ•°ç´¢å¼•
            bbox_idx = scale_idx + 3  # è¾¹ç•Œæ¡†ç´¢å¼•
            landmark_idx = scale_idx + 6  # å…³é”®ç‚¹ç´¢å¼•
            
            scores = outputs[score_idx][0]  # å½¢çŠ¶: [N, 1]
            bboxes = outputs[bbox_idx][0]  # å½¢çŠ¶: [N, 4]
            
            # å°†scoresä»[N, 1]è½¬æ¢ä¸º[N]
            scores = scores.flatten()
            
            # è¿‡æ»¤ä½ç½®ä¿¡åº¦çš„æ£€æµ‹
            keep_indices = scores > self.conf_threshold
            
            if not np.any(keep_indices):
                continue
            
            scale_scores = scores[keep_indices]
            scale_bboxes = bboxes[keep_indices]
            
            # åº”ç”¨NMS
            indices = self._nms(scale_bboxes, scale_scores)
            
            for idx in indices:
                score = scale_scores[idx]
                bbox = scale_bboxes[idx]
                
                # å°†è¾¹ç•Œæ¡†ä»resizedå°ºå¯¸æ˜ å°„å›åŸå§‹å°ºå¯¸
                x1, y1, x2, y2 = bbox[:4]
                
                # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
                scale_x = original_size[0] / resized_size[0]
                scale_y = original_size[1] / resized_size[1]
                
                # æ˜ å°„åˆ°åŸå§‹å›¾åƒ
                x1 = int(x1 * scale_x)
                y1 = int(y1 * scale_y)
                x2 = int(x2 * scale_x)
                y2 = int(y2 * scale_y)
                
                # ç¡®ä¿è¾¹ç•Œæ¡†åœ¨å›¾åƒèŒƒå›´å†…
                x1 = max(0, x1)
                y1 = max(0, y1)
                x2 = min(original_size[0], x2)
                y2 = min(original_size[1], y2)
                
                # ç¡®ä¿è¾¹ç•Œæ¡†æœ‰æ•ˆ
                if x2 > x1 and y2 > y1:
                    all_detections.append({
                        'bbox': (x1, y1, x2, y2),
                        'score': float(score),
                        'width': x2 - x1,
                        'height': y2 - y1
                    })
        
        return all_detections
    
    def _nms(self, boxes, scores):
        """éæå¤§å€¼æŠ‘åˆ¶"""
        if len(boxes) == 0:
            return []
        
        x1 = boxes[:, 0]
        y1 = boxes[:, 1]
        x2 = boxes[:, 2]
        y2 = boxes[:, 3]
        
        areas = (x2 - x1 + 1) * (y2 - y1 + 1)
        order = scores.argsort()[::-1]
        
        keep = []
        while order.size > 0:
            i = order[0]
            keep.append(i)
            
            xx1 = np.maximum(x1[i], x1[order[1:]])
            yy1 = np.maximum(y1[i], y1[order[1:]])
            xx2 = np.minimum(x2[i], x2[order[1:]])
            yy2 = np.minimum(y2[i], y2[order[1:]])
            
            w = np.maximum(0.0, xx2 - xx1 + 1)
            h = np.maximum(0.0, yy2 - yy1 + 1)
            inter = w * h
            
            ovr = inter / (areas[i] + areas[order[1:]] - inter)
            
            inds = np.where(ovr <= self.nms_threshold)[0]
            order = order[inds + 1]
        
        return keep
    
    def detect(self, image):
        """
        æ£€æµ‹å•å¼ å›¾åƒä¸­çš„äººè„¸
        
        Args:
            image: è¾“å…¥å›¾åƒ (BGRæ ¼å¼)
            
        Returns:
            detections: æ£€æµ‹ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«bbox, scoreç­‰ä¿¡æ¯
        """
        original_size = (image.shape[1], image.shape[0])  # (width, height)
        
        # é¢„å¤„ç†
        input_data, resized_img = self._preprocess(image)
        resized_size = (resized_img.shape[1], resized_img.shape[0])
        
        # æ¨ç†
        outputs = self.net.run(None, {self.input_name: input_data})
        
        # åå¤„ç†
        detections = self._postprocess(outputs, original_size, resized_size)
        
        return detections
    
    def detect_from_file(self, image_path):
        """
        ä»æ–‡ä»¶æ£€æµ‹äººè„¸
        
        Args:
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            
        Returns:
            detections: æ£€æµ‹ç»“æœ
            image: åŸå§‹å›¾åƒ
        """
        # è¯»å–å›¾åƒ
        image = cv2.imread(str(image_path))
        if image is None:
            print(f"âŒ æ— æ³•è¯»å–å›¾åƒ: {image_path}")
            return None, None
        
        # æ£€æµ‹äººè„¸
        detections = self.detect(image)
        
        return detections, image
    
    def draw_detections(self, image, detections):
        """
        åœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœ
        
        Args:
            image: åŸå§‹å›¾åƒ
            detections: æ£€æµ‹ç»“æœ
            
        Returns:
            ç»˜åˆ¶äº†æ£€æµ‹æ¡†çš„å›¾åƒ
        """
        img_with_boxes = image.copy()
        
        if detections:
            for i, det in enumerate(detections):
                bbox = det['bbox']
                score = det['score']
                x1, y1, x2, y2 = bbox
                
                # ç»˜åˆ¶è¾¹ç•Œæ¡†
                color = (0, 255, 0)  # ç»¿è‰²
                thickness = 2
                cv2.rectangle(img_with_boxes, (x1, y1), (x2, y2), color, thickness)
                
                # ç»˜åˆ¶ç½®ä¿¡åº¦
                label = f"{score:.3f}"
                label_size, base_line = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
                y_label = max(y1, label_size[1] + 10)
                
                # ç»˜åˆ¶èƒŒæ™¯
                cv2.rectangle(img_with_boxes, 
                            (x1, y_label - label_size[1] - 10),
                            (x1 + label_size[0], y_label + base_line - 10),
                            color, cv2.FILLED)
                
                # ç»˜åˆ¶æ–‡æœ¬
                cv2.putText(img_with_boxes, label, 
                          (x1, y_label - 7), 
                          cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)
            
            # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
            cv2.putText(img_with_boxes, f'Faces: {len(detections)}', 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 
                       1, (0, 0, 255), 2)
        else:
            # æœªæ£€æµ‹åˆ°äººè„¸
            cv2.putText(img_with_boxes, 'No Face Detected', 
                       (image.shape[1]//4, image.shape[0]//2), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
        
        return img_with_boxes

def process_monitoring_images(input_folder, output_folder, 
                            conf_threshold=0.5, nms_threshold=0.5,
                            save_crops=False, crop_prefix="face",
                            model_name='scrfd_10g', use_gpu=False,
                            input_size=(1280,1280), model_path=None):
    """
    å¤„ç†ç›‘æ§å›¾åƒæ–‡ä»¶å¤¹
    
    Args:
        input_folder: è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„
        output_folder: è¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„
        conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
        nms_threshold: NMSé˜ˆå€¼
        save_crops: æ˜¯å¦ä¿å­˜è£å‰ªçš„äººè„¸
        crop_prefix: äººè„¸è£å‰ªæ–‡ä»¶åå‰ç¼€
        model_name: SCRFDæ¨¡å‹åç§°
        use_gpu: æ˜¯å¦ä½¿ç”¨GPU
        input_size: è¾“å…¥å›¾åƒå°ºå¯¸ (width, height)
        model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
    """
    print("ğŸ¯ å¼€å§‹å¤„ç†ç›‘æ§å›¾åƒ...")
    print(f"ğŸ“ è¾“å…¥æ–‡ä»¶å¤¹: {input_folder}")
    print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶å¤¹: {output_folder}")
    print(f"ğŸ“Š ç½®ä¿¡åº¦é˜ˆå€¼: {conf_threshold}")
    print(f"ğŸ“Š NMSé˜ˆå€¼: {nms_threshold}")
    print(f"ğŸ¤– æ¨¡å‹: {model_name}")
    if model_path:
        print(f"ğŸ“ æ¨¡å‹è·¯å¾„: {model_path}")
    print(f"ğŸ“ è¾“å…¥å°ºå¯¸: {input_size}")
    print(f"âš¡ GPUåŠ é€Ÿ: {'æ˜¯' if use_gpu else 'å¦'}")
    print("-" * 60)
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶å¤¹
    if not os.path.exists(input_folder):
        print(f"âŒ è¾“å…¥æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {input_folder}")
        return
    
    # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
    os.makedirs(output_folder, exist_ok=True)
    
    # åˆå§‹åŒ–æ£€æµ‹å™¨
    try:
        detector = SCRFDFaceDetector(
            model_path=model_path,
            conf_threshold=conf_threshold,
            nms_threshold=nms_threshold,
            use_gpu=use_gpu,
            model_name=model_name,
            input_size=input_size
        )
    except Exception as e:
        print(f"âŒ æ— æ³•åˆå§‹åŒ–æ£€æµ‹å™¨: {e}")
        print("\nğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
        print("1. å®‰è£…ä¾èµ–: pip install onnxruntime opencv-python")
        print("2. ç¡®ä¿æ¨¡å‹æ–‡ä»¶å­˜åœ¨")
        if model_path:
            print(f"   æŒ‡å®šè·¯å¾„: {model_path}")
        else:
            print("   é»˜è®¤è·¯å¾„: ~/.scrfd_models/scrfd_10g.onnx")
        return
    
    # æ”¯æŒçš„å›¾åƒæ ¼å¼
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff',
                       '.JPG', '.JPEG', '.PNG', '.BMP', '.TIFF'}
    
    # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
    image_files = []
    for ext in image_extensions:
        image_files.extend(Path(input_folder).glob(f'*{ext}'))
        image_files.extend(Path(input_folder).glob(f'*{ext.lower()}'))
    
    # å»é‡
    image_files = list(set(image_files))
    
    if not image_files:
        print(f"âŒ æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶: {input_folder}")
        return
    
    print(f"ğŸ“Š æ‰¾åˆ° {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶")
    
    # ç»Ÿè®¡æ•°æ®
    stats = {
        'total_images': 0,
        'detected_images': 0,
        'no_face_images': 0,
        'total_faces': 0,
        'failed_images': 0
    }
    
    # å¤„ç†æ¯ä¸ªå›¾åƒ
    for image_path in tqdm(image_files, desc="æ£€æµ‹äººè„¸"):
        stats['total_images'] += 1
        
        try:
            # æ£€æµ‹äººè„¸
            detections, image = detector.detect_from_file(image_path)
            
            if image is None:
                stats['failed_images'] += 1
                continue
            
            if not detections:
                stats['no_face_images'] += 1
            else:
                stats['detected_images'] += 1
                stats['total_faces'] += len(detections)
            
            # ç»˜åˆ¶æ£€æµ‹ç»“æœ
            image_with_boxes = detector.draw_detections(image, detections)
            
            # ä¿å­˜ç»“æœå›¾åƒ
            output_filename = f"detected_{image_path.stem}.jpg"
            output_path = os.path.join(output_folder, output_filename)
            cv2.imwrite(output_path, image_with_boxes, [cv2.IMWRITE_JPEG_QUALITY, 95])
            
            # ä¿å­˜è£å‰ªçš„äººè„¸
            if save_crops and detections:
                crop_dir = os.path.join(output_folder, f"{crop_prefix}_{image_path.stem}")
                os.makedirs(crop_dir, exist_ok=True)
                
                for i, det in enumerate(detections):
                    x1, y1, x2, y2 = det['bbox']
                    face_crop = image[y1:y2, x1:x2]
                    
                    if face_crop.size > 0:
                        crop_filename = f"{crop_prefix}_{i+1:03d}.jpg"
                        crop_path = os.path.join(crop_dir, crop_filename)
                        cv2.imwrite(crop_path, face_crop, [cv2.IMWRITE_JPEG_QUALITY, 95])
            
        except Exception as e:
            stats['failed_images'] += 1
            print(f"âŒ å¤„ç†å¤±è´¥ {image_path.name}: {e}")
    
    # æ‰“å°ç»Ÿè®¡æŠ¥å‘Š
    print("\n" + "=" * 60)
    print("ğŸ“Š SCRFDæ£€æµ‹å®Œæˆï¼")
    print("=" * 60)
    print(f"ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
    print(f"  æ€»å›¾åƒæ•°: {stats['total_images']}")
    print(f"  æ£€æµ‹åˆ°äººè„¸çš„å›¾åƒ: {stats['detected_images']}")
    print(f"  æœªæ£€æµ‹åˆ°äººè„¸çš„å›¾åƒ: {stats['no_face_images']}")
    print(f"  æ£€æµ‹åˆ°çš„æ€»äººè„¸æ•°: {stats['total_faces']}")
    print(f"  å¤„ç†å¤±è´¥çš„å›¾åƒ: {stats['failed_images']}")
    
    if stats['detected_images'] > 0:
        avg_faces = stats['total_faces'] / stats['detected_images']
        print(f"  å¹³å‡æ¯å¼ å›¾åƒäººè„¸æ•°: {avg_faces:.1f}")
    
    print(f"\nğŸ“ ç»“æœä¿å­˜åˆ°: {os.path.abspath(output_folder)}")
    
    # ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶
    report_path = os.path.join(output_folder, "scrfd_detection_report.txt")
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("SCRFDäººè„¸æ£€æµ‹æŠ¥å‘Š\n")
        f.write("=" * 50 + "\n\n")
        f.write(f"è¾“å…¥æ–‡ä»¶å¤¹: {input_folder}\n")
        f.write(f"è¾“å‡ºæ–‡ä»¶å¤¹: {output_folder}\n")
        f.write(f"æ¨¡å‹: {model_name}\n")
        if model_path:
            f.write(f"æ¨¡å‹è·¯å¾„: {model_path}\n")
        f.write(f"è¾“å…¥å°ºå¯¸: {input_size}\n")
        f.write(f"ç½®ä¿¡åº¦é˜ˆå€¼: {conf_threshold}\n")
        f.write(f"NMSé˜ˆå€¼: {nms_threshold}\n")
        f.write(f"GPUåŠ é€Ÿ: {use_gpu}\n\n")
        f.write("ç»Ÿè®¡ä¿¡æ¯:\n")
        f.write(f"  æ€»å›¾åƒæ•°: {stats['total_images']}\n")
        f.write(f"  æ£€æµ‹åˆ°äººè„¸çš„å›¾åƒ: {stats['detected_images']}\n")
        f.write(f"  æœªæ£€æµ‹åˆ°äººè„¸çš„å›¾åƒ: {stats['no_face_images']}\n")
        f.write(f"  æ£€æµ‹åˆ°çš„æ€»äººè„¸æ•°: {stats['total_faces']}\n")
        f.write(f"  å¤„ç†å¤±è´¥çš„å›¾åƒ: {stats['failed_images']}\n")
        if stats['detected_images'] > 0:
            f.write(f"  å¹³å‡æ¯å¼ å›¾åƒäººè„¸æ•°: {stats['total_faces']/stats['detected_images']:.1f}\n")
    
    print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Š: {report_path}")

def main():
    parser = argparse.ArgumentParser(description="ä½¿ç”¨SCRFDæ£€æµ‹ç›‘æ§å›¾åƒä¸­çš„äººè„¸")
    parser.add_argument("input", help="ç›‘æ§å›¾åƒæ–‡ä»¶å¤¹è·¯å¾„", nargs='?', default="196")
    parser.add_argument("-o", "--output", default="scrfd_results", 
                       help="è¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„ï¼Œé»˜è®¤: scrfd_results")
    parser.add_argument("-c", "--conf", type=float, default=0.5,
                       help="ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œé»˜è®¤: 0.5")
    parser.add_argument("-n", "--nms", type=float, default=0.5,
                       help="NMSé˜ˆå€¼ï¼Œé»˜è®¤: 0.5")
    parser.add_argument("-m", "--model", default="scrfd_10g",
                       choices=['scrfd_500m', 'scrfd_2.5g', 'scrfd_10g'], 
                       help="SCRFDæ¨¡å‹ï¼Œé»˜è®¤: scrfd_10g")
    parser.add_argument("--model-path", default="/hdd/f25/zgq/retina_face_test/scrfd_10g_bnkps.onnx",
                       help="SCRFDæ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤: /hdd/f25/zgq/retina_face_test/scrfd_10g_bnkps.onnx")
    parser.add_argument("--input-size", type=int, nargs=2, default=[1280, 1280],
                       metavar=('WIDTH', 'HEIGHT'),
                       help="è¾“å…¥å›¾åƒå°ºå¯¸ï¼Œé»˜è®¤: 640 640")
    parser.add_argument("--gpu", action="store_true",
                       help="ä½¿ç”¨GPUåŠ é€Ÿï¼ˆéœ€è¦onnxruntime-gpuï¼‰")
    parser.add_argument("--save-crops", action="store_true",
                       help="ä¿å­˜è£å‰ªçš„äººè„¸å›¾åƒ")
    
    args = parser.parse_args()
    
    print("ğŸ¤– SCRFDäººè„¸æ£€æµ‹å™¨ - ä¸“ä¸ºç›‘æ§åœºæ™¯ä¼˜åŒ–")
    print("=" * 60)
    
    # æ£€æŸ¥è¾“å…¥è·¯å¾„
    if not os.path.exists(args.input):
        print(f"âŒ è¾“å…¥è·¯å¾„ä¸å­˜åœ¨: {args.input}")
        return
    
    # å¤„ç†å›¾åƒ
    if os.path.isdir(args.input):
        process_monitoring_images(
            input_folder=args.input,
            output_folder=args.output,
            conf_threshold=args.conf,
            nms_threshold=args.nms,
            save_crops=args.save_crops,
            model_name=args.model,
            use_gpu=args.gpu,
            input_size=tuple(args.input_size),
            model_path=args.model_path
        )
    elif os.path.isfile(args.input):
        # å•å¼ å›¾åƒå¤„ç†
        print(f"ğŸ” å¤„ç†å•å¼ å›¾åƒ: {args.input}")
        
        # åˆå§‹åŒ–æ£€æµ‹å™¨
        detector = SCRFDFaceDetector(
            model_path=args.model_path,  # ä½¿ç”¨args.model_path
            conf_threshold=args.conf,
            nms_threshold=args.nms,
            use_gpu=args.gpu,
            model_name=args.model,
            input_size=tuple(args.input_size)
        )
        
        # æ£€æµ‹äººè„¸
        detections, image = detector.detect_from_file(args.input)
        
        if image is None:
            print("âŒ æ— æ³•è¯»å–å›¾åƒ")
            return
        
        if detections:
            print(f"âœ… æ£€æµ‹åˆ° {len(detections)} å¼ äººè„¸")
            for i, det in enumerate(detections):
                print(f"  ğŸ‘¤ äººè„¸ {i+1}: ç½®ä¿¡åº¦={det['score']:.3f}, ä½ç½®={det['bbox']}, å¤§å°={det['width']}x{det['height']}")
        else:
            print("âŒ æœªæ£€æµ‹åˆ°äººè„¸")
        
        # ä¿å­˜ç»“æœ
        output_path = f"detected_{Path(args.input).stem}.jpg"
        image_with_boxes = detector.draw_detections(image, detections)
        cv2.imwrite(output_path, image_with_boxes, [cv2.IMWRITE_JPEG_QUALITY, 95])
        print(f"âœ… ç»“æœå·²ä¿å­˜: {output_path}")
    else:
        print(f"âŒ æ— æ•ˆçš„è¾“å…¥è·¯å¾„: {args.input}")

if __name__ == "__main__":
    # æ£€æŸ¥ä¾èµ–
    try:
        import onnxruntime
    except ImportError:
        print("âŒ éœ€è¦å®‰è£… onnxruntime")
        print("å®‰è£…å‘½ä»¤:")
        print("  CPUç‰ˆæœ¬: pip install onnxruntime")
        print("  GPUç‰ˆæœ¬: pip install onnxruntime-gpu")
        exit(1)
    
    main()