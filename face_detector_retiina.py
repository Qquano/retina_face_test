#!/usr/bin/env python3
"""
ä½¿ç”¨RetinaFaceæ£€æµ‹äººè„¸å¹¶ä¿å­˜æ¡†é€‰å›¾åƒ
"""

import os
import cv2
import numpy as np
from retinaface import RetinaFace
from pathlib import Path
import argparse
from tqdm import tqdm

class FaceDetector:
    def __init__(self, threshold=0.5, save_boxes=True, show_score=True):
        """
        åˆå§‹åŒ–äººè„¸æ£€æµ‹å™¨
        
        Args:
            threshold: ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œé»˜è®¤0.5
            save_boxes: æ˜¯å¦ä¿å­˜æ¡†é€‰å›¾åƒ
            show_score: æ˜¯å¦åœ¨å›¾åƒä¸Šæ˜¾ç¤ºç½®ä¿¡åº¦
        """
        self.threshold = threshold
        self.save_boxes = save_boxes
        self.show_score = show_score
        
        # åˆå§‹åŒ–æ£€æµ‹å™¨
        print("ğŸ”„ åˆå§‹åŒ–RetinaFaceæ£€æµ‹å™¨...")
        self.detector = RetinaFace.build_model()
        print("âœ… æ£€æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def detect_faces_in_image(self, image_path):
        """
        æ£€æµ‹å•å¼ å›¾åƒä¸­çš„äººè„¸
        
        Args:
            image_path: å›¾åƒè·¯å¾„
            
        Returns:
            faces: æ£€æµ‹åˆ°çš„äººè„¸ä¿¡æ¯
            image_with_boxes: å¸¦æ¡†é€‰çš„å›¾åƒ
        """
        # è¯»å–å›¾åƒ
        img = cv2.imread(str(image_path))
        if img is None:
            print(f"âŒ æ— æ³•è¯»å–å›¾åƒ: {image_path}")
            return None, None
        
        # ä½¿ç”¨RetinaFaceæ£€æµ‹äººè„¸
        faces = RetinaFace.detect_faces(img, threshold=self.threshold)
        
        # å¤åˆ¶å›¾åƒç”¨äºç»˜åˆ¶
        img_with_boxes = img.copy()
        
        if isinstance(faces, dict) and faces:
            # æ£€æµ‹åˆ°äººè„¸
            face_count = len(faces)
            
            for face_id, face_info in faces.items():
                # è·å–äººè„¸æ¡†å’Œç½®ä¿¡åº¦
                facial_area = face_info['facial_area']
                score = face_info['score']
                
                # ç»˜åˆ¶äººè„¸æ¡†
                x1, y1, x2, y2 = facial_area
                cv2.rectangle(img_with_boxes, (x1, y1), (x2, y2), (0, 255, 0), 2)
                
                # æ˜¾ç¤ºç½®ä¿¡åº¦
                if self.show_score:
                    cv2.putText(img_with_boxes, f'{score:.3f}', 
                              (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 
                              0.5, (0, 255, 0), 1)
                
                # ç»˜åˆ¶å…³é”®ç‚¹ï¼ˆå¯é€‰ï¼‰
                landmarks = face_info['landmarks']
                colors = {'left_eye': (255, 0, 0),   # è“è‰²
                         'right_eye': (0, 0, 255),  # çº¢è‰²
                         'nose': (0, 255, 0),       # ç»¿è‰²
                         'mouth_left': (0, 255, 255),  # é»„è‰²
                         'mouth_right': (255, 0, 255)}  # ç´«è‰²
                
                for landmark_name, point in landmarks.items():
                    color = colors.get(landmark_name, (255, 255, 255))
                    cv2.circle(img_with_boxes, 
                              (int(point[0]), int(point[1])), 
                              3, color, -1)
            
            # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
            cv2.putText(img_with_boxes, f'Faces: {face_count}', 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 
                       1, (0, 0, 255), 2)
        else:
            # æœªæ£€æµ‹åˆ°äººè„¸
            cv2.putText(img_with_boxes, 'No Face Detected', 
                       (img.shape[1]//4, img.shape[0]//2), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
            faces = None
        
        return faces, img_with_boxes
    
    def save_detection_result(self, original_image, image_with_boxes, faces, 
                             output_path, save_crops=False, crop_output_dir=None):
        """
        ä¿å­˜æ£€æµ‹ç»“æœ
        
        Args:
            original_image: åŸå§‹å›¾åƒ
            image_with_boxes: å¸¦æ¡†é€‰çš„å›¾åƒ
            faces: æ£€æµ‹åˆ°çš„äººè„¸ä¿¡æ¯
            output_path: è¾“å‡ºè·¯å¾„
            save_crops: æ˜¯å¦ä¿å­˜è£å‰ªçš„äººè„¸
            crop_output_dir: äººè„¸è£å‰ªä¿å­˜ç›®å½•
        """
        try:
            # ä¿å­˜å¸¦æ¡†é€‰çš„å›¾åƒ
            cv2.imwrite(output_path, image_with_boxes, 
                       [cv2.IMWRITE_JPEG_QUALITY, 95])
            
            # å¦‚æœéœ€è¦ä¿å­˜è£å‰ªçš„äººè„¸
            if save_crops and faces and isinstance(faces, dict):
                os.makedirs(crop_output_dir, exist_ok=True)
                
                for i, (face_id, face_info) in enumerate(faces.items()):
                    facial_area = face_info['facial_area']
                    x1, y1, x2, y2 = facial_area
                    
                    # è£å‰ªäººè„¸
                    face_crop = original_image[y1:y2, x1:x2]
                    
                    if face_crop.size > 0:
                        # ä¿å­˜è£å‰ªçš„äººè„¸
                        crop_filename = f"face_{i+1:03d}.jpg"
                        crop_path = os.path.join(crop_output_dir, crop_filename)
                        cv2.imwrite(crop_path, face_crop, 
                                   [cv2.IMWRITE_JPEG_QUALITY, 95])
            
            return True
        except Exception as e:
            print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")
            return False

def process_folder(input_folder, output_folder, threshold=0.5, 
                   save_crops=False, crop_prefix="crop"):
    """
    å¤„ç†æ•´ä¸ªæ–‡ä»¶å¤¹çš„å›¾åƒ
    
    Args:
        input_folder: è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„
        output_folder: è¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„
        threshold: æ£€æµ‹é˜ˆå€¼
        save_crops: æ˜¯å¦ä¿å­˜è£å‰ªçš„äººè„¸
        crop_prefix: äººè„¸è£å‰ªæ–‡ä»¶å¤¹å‰ç¼€
    """
    print("ğŸ¯ å¼€å§‹å¤„ç†ç›‘æ§å›¾åƒ...")
    print(f"ğŸ“ è¾“å…¥æ–‡ä»¶å¤¹: {input_folder}")
    print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶å¤¹: {output_folder}")
    print(f"ğŸ“Š æ£€æµ‹é˜ˆå€¼: {threshold}")
    print("-" * 60)
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶å¤¹
    if not os.path.exists(input_folder):
        print(f"âŒ è¾“å…¥æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {input_folder}")
        return
    
    # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
    os.makedirs(output_folder, exist_ok=True)
    
    # åˆå§‹åŒ–æ£€æµ‹å™¨
    detector = FaceDetector(threshold=threshold)
    
    # æ”¯æŒçš„å›¾åƒæ ¼å¼
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', 
                       '.JPG', '.JPEG', '.PNG', '.BMP'}
    
    # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
    image_files = []
    for ext in image_extensions:
        image_files.extend(Path(input_folder).glob(f'*{ext}'))
    
    if not image_files:
        print(f"âŒ æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶: {input_folder}")
        return
    
    print(f"ğŸ“Š æ‰¾åˆ° {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶")
    
    # ç»Ÿè®¡æ•°æ®
    stats = {
        'total_images': 0,
        'detected_images': 0,
        'no_face_images': 0,
        'total_faces': 0,
        'failed_images': 0
    }
    
    # å¤„ç†æ¯ä¸ªå›¾åƒ
    for image_path in tqdm(image_files, desc="æ£€æµ‹äººè„¸"):
        stats['total_images'] += 1
        
        try:
            # æ£€æµ‹äººè„¸
            faces, img_with_boxes = detector.detect_faces_in_image(image_path)
            
            if faces is None:
                stats['no_face_images'] += 1
            else:
                stats['detected_images'] += 1
                stats['total_faces'] += len(faces)
            
            # æ„å»ºè¾“å‡ºè·¯å¾„
            output_filename = f"detected_{image_path.stem}.jpg"
            output_path = os.path.join(output_folder, output_filename)
            
            # å¦‚æœéœ€è¦ä¿å­˜è£å‰ªçš„äººè„¸
            crop_output_dir = None
            if save_crops and faces:
                crop_dir_name = f"{crop_prefix}_{image_path.stem}"
                crop_output_dir = os.path.join(output_folder, crop_dir_name)
            
            # è¯»å–åŸå§‹å›¾åƒç”¨äºä¿å­˜è£å‰ª
            img_original = cv2.imread(str(image_path))
            
            # ä¿å­˜ç»“æœ
            detector.save_detection_result(
                img_original, img_with_boxes, faces, 
                output_path, save_crops, crop_output_dir
            )
            
        except Exception as e:
            stats['failed_images'] += 1
            print(f"âŒ å¤„ç†å¤±è´¥ {image_path.name}: {e}")
    
    # æ‰“å°ç»Ÿè®¡æŠ¥å‘Š
    print("\n" + "=" * 60)
    print("ğŸ“Š æ£€æµ‹å®Œæˆï¼")
    print("=" * 60)
    print(f"ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
    print(f"  ğŸ“‚ æ€»å›¾åƒæ•°: {stats['total_images']}")
    print(f"  âœ… æ£€æµ‹åˆ°äººè„¸çš„å›¾åƒ: {stats['detected_images']}")
    print(f"  âš ï¸  æœªæ£€æµ‹åˆ°äººè„¸çš„å›¾åƒ: {stats['no_face_images']}")
    print(f"  ğŸ‘¤ æ£€æµ‹åˆ°çš„æ€»äººè„¸æ•°: {stats['total_faces']}")
    print(f"  âŒ å¤„ç†å¤±è´¥çš„å›¾åƒ: {stats['failed_images']}")
    
    if stats['detected_images'] > 0:
        avg_faces = stats['total_faces'] / stats['detected_images']
        print(f"  ğŸ“Š å¹³å‡æ¯å¼ å›¾åƒäººè„¸æ•°: {avg_faces:.1f}")
    
    print(f"\nğŸ“ ç»“æœä¿å­˜åˆ°: {os.path.abspath(output_folder)}")
    
    # ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶
    report_path = os.path.join(output_folder, "detection_report.txt")
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("äººè„¸æ£€æµ‹æŠ¥å‘Š\n")
        f.write("=" * 50 + "\n\n")
        f.write(f"è¾“å…¥æ–‡ä»¶å¤¹: {input_folder}\n")
        f.write(f"è¾“å‡ºæ–‡ä»¶å¤¹: {output_folder}\n")
        f.write(f"æ£€æµ‹é˜ˆå€¼: {threshold}\n\n")
        f.write("ç»Ÿè®¡ä¿¡æ¯:\n")
        f.write(f"  æ€»å›¾åƒæ•°: {stats['total_images']}\n")
        f.write(f"  æ£€æµ‹åˆ°äººè„¸çš„å›¾åƒ: {stats['detected_images']}\n")
        f.write(f"  æœªæ£€æµ‹åˆ°äººè„¸çš„å›¾åƒ: {stats['no_face_images']}\n")
        f.write(f"  æ£€æµ‹åˆ°çš„æ€»äººè„¸æ•°: {stats['total_faces']}\n")
        f.write(f"  å¤„ç†å¤±è´¥çš„å›¾åƒ: {stats['failed_images']}\n")
        if stats['detected_images'] > 0:
            f.write(f"  å¹³å‡æ¯å¼ å›¾åƒäººè„¸æ•°: {stats['total_faces']/stats['detected_images']:.1f}\n")
    
    print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Š: {report_path}")

def single_image_demo(image_path, output_path=None, threshold=0.5):
    """
    å•å¼ å›¾åƒæ¼”ç¤º
    
    Args:
        image_path: å›¾åƒè·¯å¾„
        output_path: è¾“å‡ºè·¯å¾„
        threshold: æ£€æµ‹é˜ˆå€¼
    """
    print(f"ğŸ” å•å¼ å›¾åƒæ¼”ç¤º: {image_path}")
    print(f"ğŸ“Š æ£€æµ‹é˜ˆå€¼: {threshold}")
    print("-" * 60)
    
    if not os.path.exists(image_path):
        print(f"âŒ å›¾åƒä¸å­˜åœ¨: {image_path}")
        return
    
    # åˆå§‹åŒ–æ£€æµ‹å™¨
    detector = FaceDetector(threshold=threshold, show_score=True)
    
    # æ£€æµ‹äººè„¸
    faces, img_with_boxes = detector.detect_faces_in_image(image_path)
    
    if faces is None:
        print("âŒ æœªæ£€æµ‹åˆ°äººè„¸")
    else:
        print(f"âœ… æ£€æµ‹åˆ° {len(faces)} å¼ äººè„¸")
        
        # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        for i, (face_id, face_info) in enumerate(faces.items()):
            facial_area = face_info['facial_area']
            score = face_info['score']
            x1, y1, x2, y2 = facial_area
            width = x2 - x1
            height = y2 - y1
            
            print(f"\nğŸ‘¤ äººè„¸ {i+1}:")
            print(f"  ğŸ¯ ç½®ä¿¡åº¦: {score:.4f}")
            print(f"  ğŸ“ ä½ç½®: ({x1}, {y1}) - ({x2}, {y2})")
            print(f"  ğŸ“ å¤§å°: {width}Ã—{height} åƒç´ ")
    
    # ä¿å­˜æˆ–æ˜¾ç¤ºç»“æœ
    if output_path:
        # ä¿å­˜ç»“æœ
        img_original = cv2.imread(image_path)
        detector.save_detection_result(img_original, img_with_boxes, faces, output_path)
        print(f"âœ… ç»“æœå·²ä¿å­˜: {output_path}")
    else:
        # æ˜¾ç¤ºç»“æœ
        cv2.imshow("Face Detection Result", img_with_boxes)
        cv2.waitKey(0)
        cv2.destroyAllWindows()

def main():
    parser = argparse.ArgumentParser(description="ä½¿ç”¨RetinaFaceæ£€æµ‹äººè„¸å¹¶ä¿å­˜æ¡†é€‰å›¾åƒ")
    parser.add_argument("input", help="è¾“å…¥æ–‡ä»¶å¤¹æˆ–å›¾åƒè·¯å¾„"ï¼Œdefault="196")
    parser.add_argument("-o", "--output", default="detection_results", 
                       help="è¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„ï¼Œé»˜è®¤: detection_results")
    parser.add_argument("-t", "--threshold", type=float, default=0.6,
                       help="æ£€æµ‹é˜ˆå€¼ï¼Œé»˜è®¤: 0.5")
    parser.add_argument("--save-crops", action="store_true",
                       help="ä¿å­˜è£å‰ªçš„äººè„¸å›¾åƒ")
    parser.add_argument("--crop-prefix", default="crop",
                       help="äººè„¸è£å‰ªæ–‡ä»¶å¤¹å‰ç¼€ï¼Œé»˜è®¤: crop")
    parser.add_argument("--demo", action="store_true",
                       help="å•å¼ å›¾åƒæ¼”ç¤ºæ¨¡å¼")
    
    args = parser.parse_args()
    
    # æ£€æŸ¥ä¾èµ–
    try:
        from retinaface import RetinaFace
    except ImportError:
        print("âŒ éœ€è¦å®‰è£… retina-face")
        print("å®‰è£…å‘½ä»¤: pip install retina-face")
        exit(1)
    
    print("ğŸ¯ RetinaFaceäººè„¸æ£€æµ‹å™¨")
    print("=" * 60)
    
    if args.demo:
        # å•å¼ å›¾åƒæ¼”ç¤ºæ¨¡å¼
        if os.path.isfile(args.input):
            output_path = f"detected_{Path(args.input).stem}.jpg"
            single_image_demo(args.input, output_path, args.threshold)
        else:
            print(f"âŒ ä¸æ˜¯æœ‰æ•ˆçš„å›¾åƒæ–‡ä»¶: {args.input}")
    else:
        # æ‰¹é‡å¤„ç†æ¨¡å¼
        if os.path.isdir(args.input):
            process_folder(args.input, args.output, args.threshold, 
                         args.save_crops, args.crop_prefix)
        elif os.path.isfile(args.input):
            print("âš ï¸  è¾“å…¥æ˜¯å•ä¸ªæ–‡ä»¶ï¼Œä½¿ç”¨ --demo å‚æ•°è¿›è¡Œæ¼”ç¤º")
            print(f"  æˆ–å°†å…¶æ”¾å…¥æ–‡ä»¶å¤¹ä¸­æ‰¹é‡å¤„ç†")
        else:
            print(f"âŒ è¾“å…¥è·¯å¾„ä¸å­˜åœ¨: {args.input}")

if __name__ == "__main__":
    main()